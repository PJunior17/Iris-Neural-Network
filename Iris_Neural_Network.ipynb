{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9hkfzI4TXMRbnqpGexwu1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PJunior17/Iris-Neural-Network/blob/main/Iris_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pWQSAq94GuQo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Prepare the Dataset"
      ],
      "metadata": {
        "id": "EXSivOD8OABE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset"
      ],
      "metadata": {
        "id": "yBoXbpVJTuWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data #is a matrix of the input features\n",
        "y = iris.target #is a list of all the output features as 0,1,2\n",
        "\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM3jA22xQ6_M",
        "outputId": "f104e510-ba98-4d59-e185-183d1d8abd31"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "k1s1ms3iTS0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split take the input features, output features, the percentage of test data and a random seed to shuffle the data\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=17)\n"
      ],
      "metadata": {
        "id": "XyOD0wo_T2dk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standardize Features"
      ],
      "metadata": {
        "id": "RULEGjjOV9z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#standardize the features\n",
        "scalar = StandardScaler() #Standardize features by removing the mean and scaling to unit variance\n",
        "Xtrain = scalar.fit_transform(Xtrain) #Fit to data, then transform it\n",
        "Xtest = scalar.transform(Xtest) #Perform standardization by centering and scaling\n",
        "\n",
        "Xtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ojE0yUeUjSX",
        "outputId": "cab0f92d-6e62-47ea-aeed-8c6fa956eb25"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.51974235,  1.8916694 , -1.32816828, -0.99726286],\n",
              "       [ 0.1771189 , -0.36704033,  0.45510661,  0.44456296],\n",
              "       [ 0.9901237 , -0.14116936,  0.845198  ,  1.49316355],\n",
              "       [-0.17131172, -0.59291131,  0.23219725,  0.18241281],\n",
              "       [ 0.40940599, -0.59291131,  0.62228864,  0.83778818],\n",
              "       [ 0.29326244, -0.14116936,  0.67801598,  0.83778818],\n",
              "       [-0.51974235, -0.14116936,  0.45510661,  0.44456296],\n",
              "       [ 2.15155912,  1.66579843,  1.68110811,  1.36208848],\n",
              "       [-0.40359881, -1.4963952 ,  0.06501523, -0.07973734],\n",
              "       [-0.17131172, -1.27052423,  0.73374332,  1.09993833],\n",
              "       [ 0.9901237 ,  0.53644356,  1.1238347 ,  1.7553137 ],\n",
              "       [-1.10046006,  0.08470162, -1.2167136 , -1.39048808],\n",
              "       [-0.17131172, -0.59291131,  0.45510661,  0.18241281],\n",
              "       [-1.2166036 ,  0.76231454, -1.16098626, -1.259413  ],\n",
              "       [ 0.75783661,  0.31057259,  0.78947066,  1.09993833],\n",
              "       [-0.86817298,  1.66579843, -1.2167136 , -1.12833793],\n",
              "       [-1.68117777, -0.14116936, -1.32816828, -1.259413  ],\n",
              "       [ 0.75783661, -0.14116936,  1.01238002,  0.83778818],\n",
              "       [ 0.52554953,  0.53644356,  1.29101672,  1.7553137 ],\n",
              "       [ 0.64169307, -0.59291131,  1.06810736,  1.36208848],\n",
              "       [ 0.52554953, -0.59291131,  0.78947066,  0.44456296],\n",
              "       [-0.75202943,  0.76231454, -1.27244094, -1.259413  ],\n",
              "       [ 0.06097536, -0.14116936,  0.78947066,  0.83778818],\n",
              "       [-0.28745527, -1.27052423,  0.12074257, -0.07973734],\n",
              "       [-0.28745527, -0.14116936,  0.45510661,  0.44456296],\n",
              "       [ 0.1771189 ,  0.76231454,  0.45510661,  0.57563803],\n",
              "       [-0.40359881, -1.72226617,  0.17646991,  0.18241281],\n",
              "       [ 0.29326244, -0.59291131,  0.5665613 ,  0.05133774],\n",
              "       [-0.86817298,  0.98818551, -1.27244094, -1.259413  ],\n",
              "       [-0.05516818, -1.04465325,  0.17646991,  0.05133774]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to Tensors"
      ],
      "metadata": {
        "id": "dltpBDU-VKdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_tensor = torch.tensor(Xtrain, dtype=torch.float32)\n",
        "Xtest_tensor = torch.tensor(Xtest, dtype=torch.float32)\n",
        "ytrain_tensor = torch.tensor(ytrain, dtype=torch.long) #need to do long because the target is full of ints and not floats\n",
        "ytest_tensor = torch.tensor(ytest, dtype=torch.long)\n",
        "\n",
        "type(Xtest_tensor), Xtest_tensor.dtype, type(ytrain_tensor), ytrain_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amwLWXhvWFWN",
        "outputId": "d6139400-1ffe-48e8-ca2b-74f632304985"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, torch.float32, torch.Tensor, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEtyLmwFWfM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Model"
      ],
      "metadata": {
        "id": "NDnmoxKRXcvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.fc1 = nn.Linear(4,10) # the first number is the number of input features you have and the second is how many neurons is it going to\n",
        "    self.fc2 = nn.Linear (10, 3) #this is the next layer and it takes all 10 outputs from the last layer and spits out 3 outputs which is our target\n",
        "\n",
        "  #when using nn.Module we have to also define the forward propagation method forward()\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "COtDF6uTXguY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model() #instantiate the model\n",
        "loss_fn = nn.CrossEntropyLoss() #loss function we are using\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2) #gradient descent algorithm"
      ],
      "metadata": {
        "id": "ds7254spaQSg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "k4RK_rm0c5fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train() #telling pytorch that we are changing the mode to change\n",
        "  optimizer.zero_grad() #we are clearing the gradient descent memory so it doesn't carry through each iteration, this helps with processing and not interfering with data\n",
        "  outputs = model(Xtrain_tensor) #forward propagation\n",
        "  loss = loss_fn(outputs, ytrain_tensor) #loss function\n",
        "  loss.backward() #back propagation\n",
        "  optimizer.step() #this updates the parameters based on the gradient descent\n",
        "\n",
        "  print('Epoch: %s | Loss: %s' % (epoch, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10Rif9NJdedJ",
        "outputId": "7a4e28b8-f62f-4ec0-809a-1f64c107a86b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: tensor(0.0287, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 1 | Loss: tensor(0.0286, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 2 | Loss: tensor(0.0286, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 3 | Loss: tensor(0.0286, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 4 | Loss: tensor(0.0286, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 5 | Loss: tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 6 | Loss: tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 7 | Loss: tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 8 | Loss: tensor(0.0285, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 9 | Loss: tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 10 | Loss: tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 11 | Loss: tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 12 | Loss: tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 13 | Loss: tensor(0.0284, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 14 | Loss: tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 15 | Loss: tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 16 | Loss: tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 17 | Loss: tensor(0.0283, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 18 | Loss: tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 19 | Loss: tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 20 | Loss: tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 21 | Loss: tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 22 | Loss: tensor(0.0282, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 23 | Loss: tensor(0.0281, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 24 | Loss: tensor(0.0281, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 25 | Loss: tensor(0.0281, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 26 | Loss: tensor(0.0281, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 27 | Loss: tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 28 | Loss: tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 29 | Loss: tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 30 | Loss: tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 31 | Loss: tensor(0.0280, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 32 | Loss: tensor(0.0279, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 33 | Loss: tensor(0.0279, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 34 | Loss: tensor(0.0279, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 35 | Loss: tensor(0.0279, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 36 | Loss: tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 37 | Loss: tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 38 | Loss: tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 39 | Loss: tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 40 | Loss: tensor(0.0278, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 41 | Loss: tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 42 | Loss: tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 43 | Loss: tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 44 | Loss: tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 45 | Loss: tensor(0.0277, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 46 | Loss: tensor(0.0276, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 47 | Loss: tensor(0.0276, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 48 | Loss: tensor(0.0276, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 49 | Loss: tensor(0.0276, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 50 | Loss: tensor(0.0276, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 51 | Loss: tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 52 | Loss: tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 53 | Loss: tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 54 | Loss: tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 55 | Loss: tensor(0.0275, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 56 | Loss: tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 57 | Loss: tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 58 | Loss: tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 59 | Loss: tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 60 | Loss: tensor(0.0274, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 61 | Loss: tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 62 | Loss: tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 63 | Loss: tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 64 | Loss: tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 65 | Loss: tensor(0.0273, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 66 | Loss: tensor(0.0272, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 67 | Loss: tensor(0.0272, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 68 | Loss: tensor(0.0272, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 69 | Loss: tensor(0.0272, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 70 | Loss: tensor(0.0272, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 71 | Loss: tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 72 | Loss: tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 73 | Loss: tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 74 | Loss: tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 75 | Loss: tensor(0.0271, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 76 | Loss: tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 77 | Loss: tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 78 | Loss: tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 79 | Loss: tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 80 | Loss: tensor(0.0270, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 81 | Loss: tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 82 | Loss: tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 83 | Loss: tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 84 | Loss: tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 85 | Loss: tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 86 | Loss: tensor(0.0269, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 87 | Loss: tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 88 | Loss: tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 89 | Loss: tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 90 | Loss: tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 91 | Loss: tensor(0.0268, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 92 | Loss: tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 93 | Loss: tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 94 | Loss: tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 95 | Loss: tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 96 | Loss: tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 97 | Loss: tensor(0.0267, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 98 | Loss: tensor(0.0266, grad_fn=<NllLossBackward0>)\n",
            "Epoch: 99 | Loss: tensor(0.0266, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model"
      ],
      "metadata": {
        "id": "Ze7mxLkwfnDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    outputs = model(Xtest_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = accuracy_score(ytest_tensor.numpy(), predicted.numpy())\n",
        "    print('Accuracy on test set: %s' % (accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8hlfJRshbSD",
        "outputId": "8771ff7f-0da5-48c0-902b-5ae15f664e9a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ewYL7iMlhfPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}